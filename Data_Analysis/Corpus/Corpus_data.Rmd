---
title: "Corpus data"
author: "Shaohua Fang"
date: "17 November 2021"
output:
    github_document: 
    toc: TRUE
---


```{r}
# set options
options(stringsAsFactors = F)          # no automatic data transformation
options("scipen" = 100, "digits" = 12) # suppress math annotation
# activate packages
library(quanteda)
library(gutenbergr)
library(tidyverse)
library(flextable)
library(readtext)
library(quanteda)
```
```{r}
# load packages
library(igraph)
library(tm)
library(NLP)
library(openNLP)
library(openNLPdata)
library(coreNLP)
library(koRpus)
library(koRpus.lang.en)
library(phrasemachine)
library(flextable)
# load function for pos-tagging objects in R
source("https://slcladal.github.io/rscripts/POStagObject.r") 
# syntax tree drawing function
source("https://slcladal.github.io/rscripts/parsetgraph.R")
```

## reading in COCA in txt.

```{r}
my_data <- readLines("2012_acad.txt")
```


```{r}
# clean data
my_data <- my_data %>%
 str_squish() 
```

```{r}
POStag <- function(object){
  require("stringr")
  require("NLP")
  require("openNLP")
  require("openNLPdata")
  # define paths to corpus files
  corpus.tmp <- object
  # define sentence annotator
  sent_token_annotator <- openNLP::Maxent_Sent_Token_Annotator()
  # define word annotator
  word_token_annotator <- openNLP::Maxent_Word_Token_Annotator()
  # define pos annotator
  pos_tag_annotator <- openNLP::Maxent_POS_Tag_Annotator(language = "en", probs = FALSE, 
    # WARNING: YOU NEED TO INCLUDE YOUR OWN PATH HERE!                                            
    model = "/Library/Frameworks/R.framework/Versions/4.1/Resources/library/openNLPdata/models/en-pos-maxent.bin")
  # convert all file content to strings
  Corpus <- lapply(corpus.tmp, function(x){
    x <- as.String(x)  }  )
  # loop over file contents
  lapply(Corpus, function(x){
    y1 <- NLP::annotate(x, list(sent_token_annotator, word_token_annotator))
    y2<- NLP::annotate(x, pos_tag_annotator, y1)
    y2w <- subset(y2, type == "word")
    tags <- sapply(y2w$features, '[[', "POS")
    r1 <- sprintf("%s/%s", x[y2w], tags)
    r2 <- paste(r1, collapse = " ")
    return(r2)  }  )
  }
```

## pos tagging data
```{r}
textpos <- POStag(object = my_data)
tagged <- flatten_chr(textpos)
```


## This is to extract the designated verbs in the past tense.
```{r}
kwic_natural <- kwic(x = tagged, pattern = c("accepted","maintained","recalled","heard","confirmed","forgot","mentioned","found","announced","discovered","noticed","saw","acknowldged","remembered","read","revealed","doubted","negotiated","polished","scratched","packed","typed","built","painted","debated","lost","investigated","watched","knitted","visited","questioned","attacked","invaded","edited","washed","followed","typed"), window = 10) 
```

## This is to create columns POS for the verbs and one word following them by using regex
```{r}
AA <- kwic_natural %>% 
  as.data.frame() %>% 
  mutate(POS = str_extract(post, "[A-Z]+"),
         FollWord = str_extract(post, "\\S+ / \\S+"))
head(AA)
```

## This is to filter for the verbs in the VBN POS and in the not sentence-final position
## I'd want another two subsequent words that follow FollWord to be shown so that further analyses can be done on them. Have no idea how to get them. 

```{r}
BB <- AA %>% 
  as.data.frame() %>% 
  mutate(POS = str_extract(post, "[A-Z]+"),
         FollWord = str_extract(post, "\\S+ / \\S+")) %>%
  filter(POS=="VBN",
         FollWord!=". / .")
```


```{r}
kwic_natural %>%
  # convert to data frame
  as.data.frame() %>%
  # create new CleanPost where tags and words are merged
  dplyr::mutate(CleanPost = stringr::str_replace_all(post, " {0,}/ {0,}", "/")) %>%
  # extract tag of concordanced word
  dplyr::mutate(PosKeyword = stringr::str_replace(CleanPost, "/([:alnum:]{2,}) .*", "\\1")) %>%
  # extract first element after pos-tag of keyword
  dplyr::mutate(FirstWord = stringr::str_remove(CleanPost, ".*? "),
                FirstWord = stringr::str_remove_all(FirstWord, " .*")) %>%
  # extract second element after pos-tag of keyword
  dplyr::mutate(SecWord = stringr::str_remove(CleanPost, ".*? "),
                SecWord = stringr::str_remove(SecWord, ".*? "),
                SecWord = stringr::str_remove_all(SecWord, " .*")) %>%
  # extract third element after pos-tag of keyword
  dplyr::mutate(ThirdWord = stringr::str_remove(CleanPost, ".*? "),
                ThirdWord = stringr::str_remove(ThirdWord, ".*? "),
                ThirdWord = stringr::str_remove(ThirdWord, ".*? "),
                ThirdWord = stringr::str_remove_all(ThirdWord, " .*")) -> BB
# inspect results
head(BB, 20)
```

```{r}
BB <- BB %>% filter(PosKeyword=="VBN")
S1 <- BB %>% filter(str_detect(FirstWord,"that")) # S-biased
S2 <- BB %>% filter(str_detect(FirstWord,"NN|NNS|NNP"), str_detect(SecWord,"VBN"))  # S-biased
S3 <- bind_rows(S1,S2)
S3$bias <- "S-bias"
CC <- left_join(BB,S3, by="docname")
CC$bias[is.na(CC$bias)] <- "NP-biased" # decide the instances categorized as NP-biased
CC$bias <- as.factor(CC$bias)
```

## Plot 
```{r barplot_forCOCA,fig.width=4.5, fig.height=3.21, dpi=300}
ggplot(data = CC) + 
  geom_bar(mapping = aes(x = bias, y = ..prop.., group = 1), stat = "count")
```
























